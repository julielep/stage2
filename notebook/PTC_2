#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Mar  8 15:10:58 2024

@author: julie
"""

# Analyse: généralités

# Tasks to be performed on flat runs:
# * identify data path for run 13144
# * display the 16 amplifiers of a sensor/raft
# * overscan and bias correction
# * gain correction
# * display different illuminations

# *******************

# * Per set of data
#     * Identify the biasses, and the level of illumination
# * Per exposure / files / amps
#    * open the file
#    * correct for overscan and bias 
  
   

# From P. Antilogus:
# * /sps/lsst/users/antilog/web/bot/spot/Xtalk_Spot.ipynb
# * bot_frame_op.py

# From P. Astier:
# * /sps/lsst/users/astier/slac/13144/gains.list 
# * Cod.py

# # NP (from P. Antilogus): Pour les données à differents flux : /sps/lsst/groups/FocalPlane/SLAC/run5/13144  c’est un run PTC
# * le bas flux à des filtres neutres pour reduire le flux pour un temps de pose donnée … ci-joint la syntaxe des noms de directory :
#   * flat_ND_OD0.5_SDSSi_492.0_flat0_351
#       * ND_OD0.5: neutral density filter 0.5   ( l’autre solution : empty = pas de filtre )
#       * SDSSi   : filtre SDSS i
#       * 492.0   : flux de 492 e-   , le flux le plus bas est donné à 50e- …mais l’éclairement est non uniforme sur les bord c’est bien moins
#       * flat0   : première pose d’une série de 2 ( il y aussi donc le flat1 )
#       * 351     : 351 ieme pose du run
#       # Analyse: généralités

# Tasks to be performed on flat runs:
# * identify data path for run 13144
# * display the 16 amplifiers of a sensor/raft
# * overscan and bias correction
# * gain correction
# * display different illuminations


import astropy.io.fits as pyfits
import os
import sys
import matplotlib.pyplot as plt
import numpy as np
import scipy.stats as stats
from scipy.stats import linregress
import json
import bot_frame_op as bot
import pandas as pd


UnBias='1D'
#UnBias='2D'

path = "/home/julie/stage2/notebook/data_flat/"
file = 'flat_13144_flat_ND.csv' #nom du fichier


doss = pd.read_csv(path+str(file))



# Image plotting from P.A.
def plot_ccd_raw(ccd_exposure,contrast=250):
    h=list()
    for i in range(16):
        h.append(plt.hist(np.ravel(ccd_exposure[i+1].data),bins=100))

    #vmin=98000
    #vmax=102000
    window=contrast
    for i in range(16) :
    #    norm = ImageNormalize(fits[i+1].data[first_line:first_p_over,first_col:first_s_over], interval=PercentileInterval(70.))
        plt.subplot(2,8,i+1,title=i+1)
        #plt.imshow(fits[i+1].data[first_line:first_p_over,first_col:first_s_over],cmap = 'hot',origin='lower',norm=norm)

        center=(h[i][1][h[i][0].argmax()]+h[i][1][h[i][0].argmax()+1])/2
        vmin=center-window
        vmax=center+window

        plt.imshow(ccd_exposure[i+1].data,origin='lower',vmin=vmin,vmax=vmax)

        #print (np.mean(fits[i+1].data[first_line:first_p_over,first_col:first_s_over]) )
        if not(i%8 ==0) :
            figure=plt.gca()
            y_axis = figure.axes.get_yaxis()
            y_axis.set_visible(False)
        plt.colorbar()
    plt.show()
    
def parse_section(section_string) :
    # input : a fits-like section string (as in DATASEC '[y0:y1,x0:x1]')
    # output :  image section coordinate to be used in python table:  ymin , ymax ,xmin, xmax
    #
    r=section_string[1:-1].split(',')
    x=list(map(int,r[0].split(':')))
    y=list(map(int,r[1].split(':')))
    # put into pythonic way
    if y[0]<=y[1]:
        y[0] = y[0]-1
    else:
        y[1] = y[1]-1
    if x[0]<=x[1]:
        x[0] = x[0]-1
    else:
        x[1] = x[1]-1
    
    return y[0],y[1],x[0],x[1]

def SingleImageIR(actfile,gains=None):
        first_line,first_lover,first_col,first_cover=parse_section(actfile.Datasec[0])
        col_size=first_cover-first_col
        line_size=first_lover-first_line
        #
        spf=np.zeros((line_size*2,col_size*8))

        for i in range(16) :
            y1,y2,x1,x2=parse_section(actfile.Datasec[i])
            yd1,yd2,xd1,xd2=parse_section(actfile.Detsec[i])
            xdir,ydir=(1,1)
            if yd2<yd1:
                ydir=-1
                (yd2,yd1)=(yd1,yd2)
            if xd2<xd1:
                xdir=-1
                (xd2,xd1)=(xd1,xd2)
            if gains is not None:
                raft_ccd=actfile.raftbay+'_'+actfile.ccdslot
                amp='C'+actfile.Extname[i][-2:]
                spf[yd1:yd2,xd1:xd2]=actfile.Image[i][y1:y2,x1:x2][::ydir,::xdir] * gains[raft_ccd][amp]
            else:
                spf[yd1:yd2,xd1:xd2]=actfile.Image[i][y1:y2,x1:x2][::ydir,::xdir]
        return spf
                
        for i in range(16) :
            if i<8 :
                xx=i*col_size-1
                yy=0
                for x in range(first_col,first_cover) : 
                    spf[yy:yy+line_size,xx+col_size-(x-first_col)]=actfile.Image[i][first_line:first_lover,x]
            else :
                xx=(15-i)*col_size
                yy=-1
                for y in range(first_line,first_lover) :  
                    spf[yy+2*line_size-(y-first_line),xx:xx+col_size]=actfile.Image[i][y,first_col:first_cover]
                    
        return spf
    
def show_image_contrasted(image_data,contrast='auto'):
    med=np.median(image_data)
    if contrast=='auto':
        contrast = 1.5 * stats.iqr(image_data)
    #plt.imshow(image_data,origin='lower',vmin=med-contrast,vmax=med+contrast)
    plt.colorbar()

def fit (diff_var,mean) :
    diff_var_=[]
    mean_=[]    
    sat = np.where(np.max(diff_var)== diff_var)
    for i in range (len(mean)):
        if  mean[i] < 5000:
            diff_var_.append(diff_var[i])
            mean_.append(mean[i])
    a, b, r, p_value, std_err = linregress(mean_, diff_var_)
    return (a,b,sat)
#sat = indice pour laquelle la diff de std est la plus grande

def fit_quadra (diff_var,mean,mean_max) :
    x_data=[]
    y_data=[]
    sat = np.where(np.max(diff_var)== diff_var)
    for i in range (len(mean)):
        if  mean[i] < mean_max:
            y_data.append(diff_var[i])
            x_data.append(mean[i])
    y_params, v  = np.polyfit(x_data, y_data, 2, full=False, cov=True)  #équation de degré 2
    y = np.poly1d(y_params)
    return y,y_params,sat,v




def merge_data(doss, refNames) -> pd.DataFrame:
    """
    Function to get (flat0,flat1) pairs

    Parameters
    ----------
    doss : list(str)
        List of files on disk.
    refNames : list(str)
        list of reference files

    Returns
    -------
    df_merge : pandas df
        Output data (columns='full_path_flat0',
                             'full_path_flat1', 
                             'fileName_flat0', 'fileName_flat1')

    """

    ref_flat = pd.DataFrame()

    for name in refNames:
        dd = pd.read_csv(name, comment='#')
        ref_flat = pd.concat((ref_flat, dd))

    df_data = pd.DataFrame(doss, columns=['full_path'])

    df_data['fileName'] = df_data['full_path'].str.split('/').str.get(-1)

    df_merge = df_data.merge(ref_flat, left_on=['fileName'], right_on=[
                             'file_flat0'], suffixes=['', ''])

    df_merge = df_merge.merge(df_data, left_on=['file_flat1'], right_on=[
                              'fileName'], suffixes=['_flat0', '_flat1'])

    df_merge = df_merge[['full_path_flat0',
                         'full_path_flat1', 'fileName_flat0', 'fileName_flat1']]

    return df_merge

#df = merge_data(doss, doss)

def process(flat0, flat1):
    
    file_list = [flat0, flat1]
    FileUnBias=bot.InFile(dirall=file_list[:],Slow=False,verbose=False,Bias=UnBias)
    flat0_overscanned=SingleImageIR(FileUnBias.all_file[0])
    flat1_overscanned=SingleImageIR(FileUnBias.all_file[1])
    
    r = []
    
    mean =np.mean((flat0_overscanned+flat1_overscanned)/2)
    std =np.std(flat0_overscanned-flat1_overscanned)
    
    r.append((99,mean,std))
    for p in range (16):
            
        if p <=7:
            ampli_flat0=flat0_overscanned[0:2002,512*(p):(513)*(p+1)]
            ampli_flat1=flat1_overscanned[0:2002,512*(p):(513)*(p+1)]
        else :
            ampli_flat0=flat0_overscanned[2002:-1,512*(p-8):(513)*(p+1-8)]
            ampli_flat1=flat1_overscanned[2002:-1,512*(p-8):(513)*(p+1-8)]

        std = np.std(ampli_flat0-ampli_flat1)
        mean = np.mean((ampli_flat0+ampli_flat1)/2)
        
        r.append((p, mean, std))
    
    
    res = pd.DataFrame(r ,columns=['ampli','mean','std'])
    
    return res


def plot_ampli (file_name):
    """
    

    Parameters
    ----------
    file_name : TYPE
        DESCRIPTION.

    Returns
    -------
    v : TYPE
        DESCRIPTION.

    """
    #tab = np.genfromtxt(file_name, delimiter=' ') #lit les données du fichier et transforme en tableau numpy       
    fig, axs = plt.subplots(4,4,sharex=True,figsize=(18,9))
    i=0
    l=np.linspace(0,mean_max,1000)
    tab=file_name
    for ax in axs.flat:

        a_ampli,b_ampli,sat_ampli=fit((tab['std'][:]**2)/2,tab['mean'][:]) 
        y,y_params,sat,v=fit_quadra(((tab['std'][:]**2)/2)-b_ampli,tab['mean'][:],mean_max)
        ax.plot(tab['mean'][:],(((tab['std'][:]*2)/2)),'.') 
        ax.plot(l,y(l))
        ax.label_outer()
        
        #affiche la légende
        ax.text(mean_max/2,100, "HDU {:} \nGain = {:.2f}\nTurnoff = {:.4f}  ".format(i+1,1/y_params[1],tab[sat[0],i][0]), fontsize=12)
      
        i=i+1
        
        #limites des axes 
        #ax.set_xlim(0,mean_max)
        #ax.set_ylim(0,35000)
        
    #légende commune 
    fig.suptitle('PTC for R22-S11-run13144 : '+str(len(tab)-1)+' illuminations (unbias '+str(UnBias)+')')
    fig.supxlabel('mean signal (ADU)')
    fig.supylabel('var ($ADU^{2}$)')

    fig.tight_layout()
    
    #plt.savefig('PTC')
    return v


data_test = process('/home/julie/Téléchargements/CCD2-20240307T134109Z-002/CCD2/MC_C_20211207_000389_R22_S11.fits','/home/julie/Téléchargements/CCD2-20240307T134109Z-002/CCD2/MC_C_20211207_000390_R22_S11.fits')
file_name = data_test
mean_max = 60000 #valeur maximale pour faire le fit  #attention à modifier pas définis dans les fonctions
v=plot_ampli(file_name)


for i in range (len(doss['raft_sensor'])):
    data = process(doss['file_flat0'][i], doss['file_flat1'][i])
    
    
    


